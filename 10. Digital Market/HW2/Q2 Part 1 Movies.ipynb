{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** All code here is based on the models that were done in class in Excel**\n",
    "\n",
    "## Collaborative Filtering with Pearson Similarity\n",
    "Below, we loaded the data and computed the average user ratings matrix, average item ratings matrix as well as the pearson similarity matrix for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"movie_ratings_inclass.xlsx\", sheetname=0, index_col=1, header = 2)\n",
    "df2 = df.drop(['User','Avg'], axis=1).iloc[0:20]\n",
    "avguserrating = df2.mean(axis=1).values\n",
    "avgitemrating = df2.mean(axis=0).values\n",
    "df3 = df2.T.convert_objects(convert_numeric=True)\n",
    "pearsonsimilarities = df3.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code replaces the diagonal of the pearson similarity matrix with 0's and filled any NA's in the matrix with 0's. Then, a list is created where for each user, we sort the list of nearest neighbors where the first item is its nearest neighbour. Then, we shifted its own index to the back of this list so that we do not take the user as its own neighbour ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in pearsonsimilarities.index:\n",
    "    pearsonsimilarities.loc[i, i] = 0.0\n",
    "pearsonsimilarities = pearsonsimilarities.fillna(0)\n",
    "\n",
    "order = np.argsort(-pearsonsimilarities.values, axis=1)\n",
    "# Moving its own index to the back so that it would not be its own nearest neighbor\n",
    "for index, element in enumerate(order):\n",
    "    element = element[element != index]\n",
    "    element = np.append(element, index)\n",
    "    order[index] = element\n",
    "\n",
    "# Changing pandas dataframes to numpy to make it easier\n",
    "pearsonsimilaritiesnp = pearsonsimilarities.values\n",
    "df2np = df2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This gets the imputed matrix of predicted ratings. The next code finds the k nearest neighbours of those who rated the movie and bases the predicted ratings on their average weighted rating. Example: user 1 has users 5,7, 8 as its 3 nearest neighbours by that order. If I predict ratings of user 1 for movie 6 based on the 2 nearest neighbors, and only user 5 and 8 has rated that movie, I consider users 5 and 8's ratings even though user 8 is in reality, the third nearest neighbor overall for user 1.  \n",
    "Again, the following code will return both the prediction matrix and the sum of square errors between the values in prediction matrix minus the values of actual ratings for those elements that were actually rated. We will then loop it for 1-20 k nearest neighbors to find the optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def userating1(k):\n",
    "    imputed = np.zeros((20,20))\n",
    "    for a in range(0,20):\n",
    "        for i in range (0,20):\n",
    "            list2 = []\n",
    "            list3 = []\n",
    "            count1 = 0\n",
    "            count2 = 0\n",
    "            while (count1 < 20):\n",
    "                m = order[a][count1]\n",
    "                c = pearsonsimilaritiesnp[a][m]\n",
    "                d = df2np[m][i]\n",
    "                if np.isnan(d) == False:\n",
    "                    # list 3 appends all the absolute weighted similarities\n",
    "                    list3.append(abs(pearsonsimilaritiesnp[a][m]))\n",
    "                    # list 2 appends the weighted similarity*(user rating for movie i- user's avg rating)\n",
    "                    pain1 = c*(d-avguserrating[m])\n",
    "                    list2.append(pain1)\n",
    "                    count2 +=1\n",
    "                count1+= 1\n",
    "                # If we get the correct amount of nearest neighbors, this stops the loop\n",
    "                if count2 == k:\n",
    "                    break\n",
    "            # This gives the prediction for user a for movie i\n",
    "            score = sum(list2)/sum(list3)\n",
    "            imputed[a][i] = avguserrating[a] + score\n",
    "    # Calculating Errors\n",
    "    a = imputed-df2\n",
    "    b = a.multiply(a, fill_value  = 0)\n",
    "    SSE = np.nansum(b.values)\n",
    "    return(pd.DataFrame(imputed), SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>sse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>358.924667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>255.968404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>236.974243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>228.657748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>224.959389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>229.249790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>224.633608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>217.034198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>209.690510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>197.257359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>186.054256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>181.315568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>184.886023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>180.075340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>179.807332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>180.008695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>180.008695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>180.008695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>180.008695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>180.008695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    knn         sse\n",
       "0     1  358.924667\n",
       "1     2  255.968404\n",
       "2     3  236.974243\n",
       "3     4  228.657748\n",
       "4     5  224.959389\n",
       "5     6  229.249790\n",
       "6     7  224.633608\n",
       "7     8  217.034198\n",
       "8     9  209.690510\n",
       "9    10  197.257359\n",
       "10   11  186.054256\n",
       "11   12  181.315568\n",
       "12   13  184.886023\n",
       "13   14  180.075340\n",
       "14   15  179.807332\n",
       "15   16  180.008695\n",
       "16   17  180.008695\n",
       "17   18  180.008695\n",
       "18   19  180.008695\n",
       "19   20  180.008695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sselist1 = []\n",
    "for i in range(1,21):\n",
    "    a = userating1(i)[1]\n",
    "    sselist1.append(a)\n",
    "knnnumber = range(1,21)\n",
    "ssedata = pd.DataFrame(\n",
    "    {'knn': knnnumber,\n",
    "     'sse': sselist1,\n",
    "    }, columns=['knn','sse'])\n",
    "ssedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, it seems that the optimal k for knn is 15, which we will use.\n",
    "\n",
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.125887</td>\n",
       "      <td>3.809875</td>\n",
       "      <td>2.468465</td>\n",
       "      <td>2.997126</td>\n",
       "      <td>3.664587</td>\n",
       "      <td>3.102324</td>\n",
       "      <td>2.656372</td>\n",
       "      <td>2.673367</td>\n",
       "      <td>2.317369</td>\n",
       "      <td>3.521447</td>\n",
       "      <td>3.044063</td>\n",
       "      <td>2.934637</td>\n",
       "      <td>4.040158</td>\n",
       "      <td>2.998709</td>\n",
       "      <td>2.573670</td>\n",
       "      <td>4.267142</td>\n",
       "      <td>1.761662</td>\n",
       "      <td>4.332319</td>\n",
       "      <td>3.593288</td>\n",
       "      <td>2.319217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.988588</td>\n",
       "      <td>2.915932</td>\n",
       "      <td>3.115639</td>\n",
       "      <td>2.133721</td>\n",
       "      <td>3.057883</td>\n",
       "      <td>2.432871</td>\n",
       "      <td>2.117643</td>\n",
       "      <td>2.580919</td>\n",
       "      <td>3.000151</td>\n",
       "      <td>3.632670</td>\n",
       "      <td>3.096949</td>\n",
       "      <td>2.527106</td>\n",
       "      <td>2.173434</td>\n",
       "      <td>2.532439</td>\n",
       "      <td>2.473829</td>\n",
       "      <td>3.200056</td>\n",
       "      <td>3.763495</td>\n",
       "      <td>1.881988</td>\n",
       "      <td>2.689880</td>\n",
       "      <td>1.752868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.912954</td>\n",
       "      <td>2.094736</td>\n",
       "      <td>2.369515</td>\n",
       "      <td>3.683575</td>\n",
       "      <td>1.987374</td>\n",
       "      <td>2.466174</td>\n",
       "      <td>3.285082</td>\n",
       "      <td>1.978337</td>\n",
       "      <td>3.130212</td>\n",
       "      <td>1.539215</td>\n",
       "      <td>3.272523</td>\n",
       "      <td>2.279263</td>\n",
       "      <td>2.603694</td>\n",
       "      <td>2.982542</td>\n",
       "      <td>2.186740</td>\n",
       "      <td>1.321762</td>\n",
       "      <td>2.126969</td>\n",
       "      <td>2.364964</td>\n",
       "      <td>1.988240</td>\n",
       "      <td>3.365319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.326940</td>\n",
       "      <td>2.339844</td>\n",
       "      <td>2.388143</td>\n",
       "      <td>2.700540</td>\n",
       "      <td>2.600596</td>\n",
       "      <td>1.627711</td>\n",
       "      <td>2.937618</td>\n",
       "      <td>2.793358</td>\n",
       "      <td>3.117819</td>\n",
       "      <td>2.315239</td>\n",
       "      <td>2.864993</td>\n",
       "      <td>3.636110</td>\n",
       "      <td>1.807446</td>\n",
       "      <td>2.924626</td>\n",
       "      <td>3.392369</td>\n",
       "      <td>2.389743</td>\n",
       "      <td>3.752023</td>\n",
       "      <td>1.487925</td>\n",
       "      <td>2.007544</td>\n",
       "      <td>3.683318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.578885</td>\n",
       "      <td>2.501400</td>\n",
       "      <td>3.047309</td>\n",
       "      <td>2.395425</td>\n",
       "      <td>3.392122</td>\n",
       "      <td>2.622037</td>\n",
       "      <td>2.488853</td>\n",
       "      <td>3.083817</td>\n",
       "      <td>3.723310</td>\n",
       "      <td>2.617868</td>\n",
       "      <td>3.964756</td>\n",
       "      <td>3.011088</td>\n",
       "      <td>3.098395</td>\n",
       "      <td>3.409873</td>\n",
       "      <td>3.955804</td>\n",
       "      <td>2.317867</td>\n",
       "      <td>3.497197</td>\n",
       "      <td>3.571934</td>\n",
       "      <td>3.677112</td>\n",
       "      <td>3.248757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.901324</td>\n",
       "      <td>4.029951</td>\n",
       "      <td>3.009891</td>\n",
       "      <td>3.663975</td>\n",
       "      <td>3.313767</td>\n",
       "      <td>3.323299</td>\n",
       "      <td>3.158363</td>\n",
       "      <td>2.218895</td>\n",
       "      <td>2.993365</td>\n",
       "      <td>4.031558</td>\n",
       "      <td>3.873461</td>\n",
       "      <td>2.121943</td>\n",
       "      <td>4.000037</td>\n",
       "      <td>2.838593</td>\n",
       "      <td>1.655562</td>\n",
       "      <td>3.619244</td>\n",
       "      <td>2.748993</td>\n",
       "      <td>3.299288</td>\n",
       "      <td>2.454697</td>\n",
       "      <td>2.453458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.567399</td>\n",
       "      <td>1.529158</td>\n",
       "      <td>3.113060</td>\n",
       "      <td>2.175780</td>\n",
       "      <td>2.513765</td>\n",
       "      <td>3.185910</td>\n",
       "      <td>2.764587</td>\n",
       "      <td>3.567647</td>\n",
       "      <td>2.323389</td>\n",
       "      <td>2.179307</td>\n",
       "      <td>1.930943</td>\n",
       "      <td>2.658001</td>\n",
       "      <td>2.259856</td>\n",
       "      <td>2.175000</td>\n",
       "      <td>2.778515</td>\n",
       "      <td>1.777193</td>\n",
       "      <td>2.325736</td>\n",
       "      <td>2.792869</td>\n",
       "      <td>3.540116</td>\n",
       "      <td>2.824637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.514328</td>\n",
       "      <td>3.031754</td>\n",
       "      <td>1.988014</td>\n",
       "      <td>1.799454</td>\n",
       "      <td>2.775932</td>\n",
       "      <td>2.795472</td>\n",
       "      <td>2.537641</td>\n",
       "      <td>3.030631</td>\n",
       "      <td>2.282562</td>\n",
       "      <td>2.746412</td>\n",
       "      <td>2.828054</td>\n",
       "      <td>2.144753</td>\n",
       "      <td>2.837773</td>\n",
       "      <td>2.326532</td>\n",
       "      <td>3.466282</td>\n",
       "      <td>3.619402</td>\n",
       "      <td>1.919753</td>\n",
       "      <td>3.713291</td>\n",
       "      <td>4.156083</td>\n",
       "      <td>2.860030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.650760</td>\n",
       "      <td>1.960428</td>\n",
       "      <td>3.351168</td>\n",
       "      <td>3.515065</td>\n",
       "      <td>2.621152</td>\n",
       "      <td>3.134144</td>\n",
       "      <td>3.872102</td>\n",
       "      <td>3.731547</td>\n",
       "      <td>3.544526</td>\n",
       "      <td>2.412741</td>\n",
       "      <td>2.995182</td>\n",
       "      <td>3.572298</td>\n",
       "      <td>2.399526</td>\n",
       "      <td>3.780511</td>\n",
       "      <td>4.530988</td>\n",
       "      <td>1.999423</td>\n",
       "      <td>3.485569</td>\n",
       "      <td>2.459768</td>\n",
       "      <td>3.110284</td>\n",
       "      <td>4.022902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.895273</td>\n",
       "      <td>2.232604</td>\n",
       "      <td>3.870131</td>\n",
       "      <td>4.047578</td>\n",
       "      <td>2.657119</td>\n",
       "      <td>3.249615</td>\n",
       "      <td>3.680903</td>\n",
       "      <td>3.436299</td>\n",
       "      <td>4.137508</td>\n",
       "      <td>3.085499</td>\n",
       "      <td>3.176070</td>\n",
       "      <td>3.475341</td>\n",
       "      <td>2.360364</td>\n",
       "      <td>3.587308</td>\n",
       "      <td>3.287793</td>\n",
       "      <td>2.135742</td>\n",
       "      <td>4.102399</td>\n",
       "      <td>1.827758</td>\n",
       "      <td>2.260609</td>\n",
       "      <td>3.852409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.022385</td>\n",
       "      <td>1.583050</td>\n",
       "      <td>3.538895</td>\n",
       "      <td>3.738522</td>\n",
       "      <td>2.434761</td>\n",
       "      <td>3.539361</td>\n",
       "      <td>3.624124</td>\n",
       "      <td>3.105597</td>\n",
       "      <td>3.410328</td>\n",
       "      <td>2.394786</td>\n",
       "      <td>2.702986</td>\n",
       "      <td>3.240715</td>\n",
       "      <td>2.435015</td>\n",
       "      <td>3.194068</td>\n",
       "      <td>2.664088</td>\n",
       "      <td>1.636937</td>\n",
       "      <td>3.299081</td>\n",
       "      <td>2.259429</td>\n",
       "      <td>2.050339</td>\n",
       "      <td>3.394597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.472253</td>\n",
       "      <td>3.947486</td>\n",
       "      <td>2.047351</td>\n",
       "      <td>2.635083</td>\n",
       "      <td>3.061412</td>\n",
       "      <td>2.452677</td>\n",
       "      <td>2.236018</td>\n",
       "      <td>2.087771</td>\n",
       "      <td>2.568666</td>\n",
       "      <td>4.028625</td>\n",
       "      <td>2.512130</td>\n",
       "      <td>2.773786</td>\n",
       "      <td>3.304721</td>\n",
       "      <td>2.033686</td>\n",
       "      <td>2.196265</td>\n",
       "      <td>3.994017</td>\n",
       "      <td>1.667015</td>\n",
       "      <td>2.966209</td>\n",
       "      <td>3.031615</td>\n",
       "      <td>1.985445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.823899</td>\n",
       "      <td>3.543119</td>\n",
       "      <td>4.444036</td>\n",
       "      <td>4.026062</td>\n",
       "      <td>3.793119</td>\n",
       "      <td>4.394619</td>\n",
       "      <td>3.839588</td>\n",
       "      <td>4.226938</td>\n",
       "      <td>3.333401</td>\n",
       "      <td>3.939242</td>\n",
       "      <td>2.680818</td>\n",
       "      <td>3.029840</td>\n",
       "      <td>4.473829</td>\n",
       "      <td>3.975737</td>\n",
       "      <td>2.835887</td>\n",
       "      <td>3.519773</td>\n",
       "      <td>3.207538</td>\n",
       "      <td>4.253426</td>\n",
       "      <td>4.318568</td>\n",
       "      <td>3.229943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.014222</td>\n",
       "      <td>3.566829</td>\n",
       "      <td>2.107019</td>\n",
       "      <td>2.786270</td>\n",
       "      <td>2.705683</td>\n",
       "      <td>2.694189</td>\n",
       "      <td>2.113588</td>\n",
       "      <td>1.992951</td>\n",
       "      <td>2.431743</td>\n",
       "      <td>3.761554</td>\n",
       "      <td>2.868402</td>\n",
       "      <td>1.980609</td>\n",
       "      <td>3.012868</td>\n",
       "      <td>1.944916</td>\n",
       "      <td>2.147991</td>\n",
       "      <td>3.834179</td>\n",
       "      <td>1.541710</td>\n",
       "      <td>2.795476</td>\n",
       "      <td>3.171459</td>\n",
       "      <td>2.230990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.164221</td>\n",
       "      <td>3.502096</td>\n",
       "      <td>3.886642</td>\n",
       "      <td>2.358353</td>\n",
       "      <td>3.742648</td>\n",
       "      <td>3.733895</td>\n",
       "      <td>2.534372</td>\n",
       "      <td>2.661823</td>\n",
       "      <td>2.576640</td>\n",
       "      <td>4.332797</td>\n",
       "      <td>3.095291</td>\n",
       "      <td>2.249090</td>\n",
       "      <td>3.756429</td>\n",
       "      <td>2.332030</td>\n",
       "      <td>1.929799</td>\n",
       "      <td>4.202546</td>\n",
       "      <td>3.163350</td>\n",
       "      <td>3.466870</td>\n",
       "      <td>3.939457</td>\n",
       "      <td>2.038742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.006902</td>\n",
       "      <td>2.924975</td>\n",
       "      <td>2.117867</td>\n",
       "      <td>2.779568</td>\n",
       "      <td>2.481834</td>\n",
       "      <td>1.812072</td>\n",
       "      <td>2.976445</td>\n",
       "      <td>2.486361</td>\n",
       "      <td>3.197955</td>\n",
       "      <td>1.341647</td>\n",
       "      <td>3.016596</td>\n",
       "      <td>3.139452</td>\n",
       "      <td>3.066937</td>\n",
       "      <td>3.228790</td>\n",
       "      <td>3.727807</td>\n",
       "      <td>2.755635</td>\n",
       "      <td>2.270164</td>\n",
       "      <td>3.699232</td>\n",
       "      <td>2.519407</td>\n",
       "      <td>3.912726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.324375</td>\n",
       "      <td>3.495870</td>\n",
       "      <td>2.547460</td>\n",
       "      <td>2.300038</td>\n",
       "      <td>3.578295</td>\n",
       "      <td>3.039995</td>\n",
       "      <td>1.833315</td>\n",
       "      <td>2.509689</td>\n",
       "      <td>2.031370</td>\n",
       "      <td>3.799601</td>\n",
       "      <td>2.036274</td>\n",
       "      <td>2.912253</td>\n",
       "      <td>3.186000</td>\n",
       "      <td>2.287498</td>\n",
       "      <td>2.610773</td>\n",
       "      <td>3.967698</td>\n",
       "      <td>2.604800</td>\n",
       "      <td>3.269010</td>\n",
       "      <td>3.289360</td>\n",
       "      <td>1.601918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.294214</td>\n",
       "      <td>3.238111</td>\n",
       "      <td>2.600474</td>\n",
       "      <td>4.289855</td>\n",
       "      <td>2.391573</td>\n",
       "      <td>2.059570</td>\n",
       "      <td>3.579037</td>\n",
       "      <td>2.878757</td>\n",
       "      <td>3.496710</td>\n",
       "      <td>2.479210</td>\n",
       "      <td>3.745025</td>\n",
       "      <td>3.691556</td>\n",
       "      <td>2.841375</td>\n",
       "      <td>3.130646</td>\n",
       "      <td>3.487406</td>\n",
       "      <td>2.861135</td>\n",
       "      <td>3.137600</td>\n",
       "      <td>2.415914</td>\n",
       "      <td>2.365042</td>\n",
       "      <td>3.712216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.468367</td>\n",
       "      <td>1.942937</td>\n",
       "      <td>3.467535</td>\n",
       "      <td>2.315975</td>\n",
       "      <td>2.783911</td>\n",
       "      <td>2.936734</td>\n",
       "      <td>2.526955</td>\n",
       "      <td>2.204342</td>\n",
       "      <td>2.712550</td>\n",
       "      <td>3.073534</td>\n",
       "      <td>3.288228</td>\n",
       "      <td>1.735952</td>\n",
       "      <td>2.080328</td>\n",
       "      <td>1.840467</td>\n",
       "      <td>2.198956</td>\n",
       "      <td>1.675534</td>\n",
       "      <td>2.561586</td>\n",
       "      <td>2.003668</td>\n",
       "      <td>2.839879</td>\n",
       "      <td>2.348955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.131359</td>\n",
       "      <td>3.297008</td>\n",
       "      <td>2.393641</td>\n",
       "      <td>2.854704</td>\n",
       "      <td>3.558171</td>\n",
       "      <td>2.888006</td>\n",
       "      <td>2.735427</td>\n",
       "      <td>3.585306</td>\n",
       "      <td>2.282475</td>\n",
       "      <td>2.064412</td>\n",
       "      <td>2.515358</td>\n",
       "      <td>3.533807</td>\n",
       "      <td>3.549958</td>\n",
       "      <td>2.647616</td>\n",
       "      <td>3.894996</td>\n",
       "      <td>3.681273</td>\n",
       "      <td>2.450744</td>\n",
       "      <td>4.433131</td>\n",
       "      <td>3.504492</td>\n",
       "      <td>3.270193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7   \\\n",
       "1   2.125887  3.809875  2.468465  2.997126  3.664587  3.102324  2.656372   \n",
       "2   3.988588  2.915932  3.115639  2.133721  3.057883  2.432871  2.117643   \n",
       "3   1.912954  2.094736  2.369515  3.683575  1.987374  2.466174  3.285082   \n",
       "4   3.326940  2.339844  2.388143  2.700540  2.600596  1.627711  2.937618   \n",
       "5   3.578885  2.501400  3.047309  2.395425  3.392122  2.622037  2.488853   \n",
       "6   2.901324  4.029951  3.009891  3.663975  3.313767  3.323299  3.158363   \n",
       "7   2.567399  1.529158  3.113060  2.175780  2.513765  3.185910  2.764587   \n",
       "8   3.514328  3.031754  1.988014  1.799454  2.775932  2.795472  2.537641   \n",
       "9   3.650760  1.960428  3.351168  3.515065  2.621152  3.134144  3.872102   \n",
       "10  3.895273  2.232604  3.870131  4.047578  2.657119  3.249615  3.680903   \n",
       "11  3.022385  1.583050  3.538895  3.738522  2.434761  3.539361  3.624124   \n",
       "12  2.472253  3.947486  2.047351  2.635083  3.061412  2.452677  2.236018   \n",
       "13  2.823899  3.543119  4.444036  4.026062  3.793119  4.394619  3.839588   \n",
       "14  3.014222  3.566829  2.107019  2.786270  2.705683  2.694189  2.113588   \n",
       "15  3.164221  3.502096  3.886642  2.358353  3.742648  3.733895  2.534372   \n",
       "16  3.006902  2.924975  2.117867  2.779568  2.481834  1.812072  2.976445   \n",
       "17  2.324375  3.495870  2.547460  2.300038  3.578295  3.039995  1.833315   \n",
       "18  3.294214  3.238111  2.600474  4.289855  2.391573  2.059570  3.579037   \n",
       "19  3.468367  1.942937  3.467535  2.315975  2.783911  2.936734  2.526955   \n",
       "20  2.131359  3.297008  2.393641  2.854704  3.558171  2.888006  2.735427   \n",
       "\n",
       "          8         9         10        11        12        13        14  \\\n",
       "1   2.673367  2.317369  3.521447  3.044063  2.934637  4.040158  2.998709   \n",
       "2   2.580919  3.000151  3.632670  3.096949  2.527106  2.173434  2.532439   \n",
       "3   1.978337  3.130212  1.539215  3.272523  2.279263  2.603694  2.982542   \n",
       "4   2.793358  3.117819  2.315239  2.864993  3.636110  1.807446  2.924626   \n",
       "5   3.083817  3.723310  2.617868  3.964756  3.011088  3.098395  3.409873   \n",
       "6   2.218895  2.993365  4.031558  3.873461  2.121943  4.000037  2.838593   \n",
       "7   3.567647  2.323389  2.179307  1.930943  2.658001  2.259856  2.175000   \n",
       "8   3.030631  2.282562  2.746412  2.828054  2.144753  2.837773  2.326532   \n",
       "9   3.731547  3.544526  2.412741  2.995182  3.572298  2.399526  3.780511   \n",
       "10  3.436299  4.137508  3.085499  3.176070  3.475341  2.360364  3.587308   \n",
       "11  3.105597  3.410328  2.394786  2.702986  3.240715  2.435015  3.194068   \n",
       "12  2.087771  2.568666  4.028625  2.512130  2.773786  3.304721  2.033686   \n",
       "13  4.226938  3.333401  3.939242  2.680818  3.029840  4.473829  3.975737   \n",
       "14  1.992951  2.431743  3.761554  2.868402  1.980609  3.012868  1.944916   \n",
       "15  2.661823  2.576640  4.332797  3.095291  2.249090  3.756429  2.332030   \n",
       "16  2.486361  3.197955  1.341647  3.016596  3.139452  3.066937  3.228790   \n",
       "17  2.509689  2.031370  3.799601  2.036274  2.912253  3.186000  2.287498   \n",
       "18  2.878757  3.496710  2.479210  3.745025  3.691556  2.841375  3.130646   \n",
       "19  2.204342  2.712550  3.073534  3.288228  1.735952  2.080328  1.840467   \n",
       "20  3.585306  2.282475  2.064412  2.515358  3.533807  3.549958  2.647616   \n",
       "\n",
       "          15        16        17        18        19        20  \n",
       "1   2.573670  4.267142  1.761662  4.332319  3.593288  2.319217  \n",
       "2   2.473829  3.200056  3.763495  1.881988  2.689880  1.752868  \n",
       "3   2.186740  1.321762  2.126969  2.364964  1.988240  3.365319  \n",
       "4   3.392369  2.389743  3.752023  1.487925  2.007544  3.683318  \n",
       "5   3.955804  2.317867  3.497197  3.571934  3.677112  3.248757  \n",
       "6   1.655562  3.619244  2.748993  3.299288  2.454697  2.453458  \n",
       "7   2.778515  1.777193  2.325736  2.792869  3.540116  2.824637  \n",
       "8   3.466282  3.619402  1.919753  3.713291  4.156083  2.860030  \n",
       "9   4.530988  1.999423  3.485569  2.459768  3.110284  4.022902  \n",
       "10  3.287793  2.135742  4.102399  1.827758  2.260609  3.852409  \n",
       "11  2.664088  1.636937  3.299081  2.259429  2.050339  3.394597  \n",
       "12  2.196265  3.994017  1.667015  2.966209  3.031615  1.985445  \n",
       "13  2.835887  3.519773  3.207538  4.253426  4.318568  3.229943  \n",
       "14  2.147991  3.834179  1.541710  2.795476  3.171459  2.230990  \n",
       "15  1.929799  4.202546  3.163350  3.466870  3.939457  2.038742  \n",
       "16  3.727807  2.755635  2.270164  3.699232  2.519407  3.912726  \n",
       "17  2.610773  3.967698  2.604800  3.269010  3.289360  1.601918  \n",
       "18  3.487406  2.861135  3.137600  2.415914  2.365042  3.712216  \n",
       "19  2.198956  1.675534  2.561586  2.003668  2.839879  2.348955  \n",
       "20  3.894996  3.681273  2.450744  4.433131  3.504492  3.270193  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionmatrix = userating1(15)[0]\n",
    "predictions = pd.DataFrame(predictionmatrix)\n",
    "# Had to plus 1 each way since user and movies start from index 1\n",
    "predictions.index = predictions.index + 1\n",
    "predictions.columns = predictions.columns + 1\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The code below is tuning for optimal lambda and gamma and the number of iterations. Errors were calculated for each iteration and then the minimum error and its corresponding number of iterations was found for each lambda, gamma pair. Afterwards, we find the optimal lambda, gamma pair that gives the lowest error.  \n",
    "\n",
    "It works by initializing the latent factor matrices with ones. Then, for each element in the original matrix, it updates the movie matrix and then calculates the squared error between the actual and prediction. Then we update the latent factor matrix given the error, lambda (regularization term) and gamma (value determining the rate of approaching the minimum or learning rate). If gamma is large, we might skip the optimal solution and end up oscillating around it. If it is too small, we might need too many iterations to converge to the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuningDF = pd.DataFrame({'lambda': [0], 'gamma': [0], \n",
    "                         'train_error_index': [0], 'train_error': [0]})\n",
    "lambdav = np.arange(0, 10, 0.01)\n",
    "gamma= np.arange(0, 0.6, 0.01)\n",
    "#lambdav = np.arange(0, 20, 0.1)\n",
    "#gamma= np.arange(0, 1, 0.2)\n",
    "for lam in lambdav:\n",
    "    for gam in gamma:\n",
    "        df4 = df2\n",
    "        df4 = df4.fillna(0)\n",
    "        # Changing pandas dataframes to numpy to make it easier\n",
    "        df4 = df4.values\n",
    "        df5 = df4.copy()\n",
    "        def sse(true):\n",
    "            return np.sum(true**2)\n",
    "        P = np.ones((20, 2))\n",
    "        Q = np.ones((2, 20))\n",
    "        \n",
    "        train_errors = []\n",
    "        num = 0\n",
    "        while num < 60:\n",
    "            S = P.copy()\n",
    "            R = Q.copy()\n",
    "            errorlist = []\n",
    "            for a in range(0,20):\n",
    "                for b in range (0,20):\n",
    "                    if df5[a,b] != 0:\n",
    "                        df4[a,b] = df5[a,b] - np.dot(R[:,b], S[a, :].T)\n",
    "                        errorlist.append((df4[a,b])**2)\n",
    "                    else:\n",
    "                        df4[a,b] = 0\n",
    "            \n",
    "            for c in range(0,20):\n",
    "                P[c, 0] += gam * (np.dot(df4[c, :], R[0,:]) - lam * P[c,0])\n",
    "                P[c, 1] += gam * (np.dot(df4[c, :], R[1,:]) - lam * P[c,1])\n",
    "                Q[0, c] += gam * (np.dot(df4[:, c], S[:,0]) - lam * Q[0, c]) \n",
    "                Q[1, c] += gam * (np.dot(df4[:, c], S[:,1]) - lam * Q[1, c]) \n",
    "            num += 1\n",
    "            train_errors.append(sum(errorlist))\n",
    "        minerrorindex = train_errors.index(min(train_errors))\n",
    "        minerror = min(train_errors)\n",
    "        var_2 = pd.DataFrame({'lambda': [lam], 'gamma': [gam], \n",
    "                              'train_error_index': [minerrorindex], 'train_error': [minerror]})\n",
    "        tuningDF = pd.concat([tuningDF, var_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>train_error</th>\n",
       "      <th>train_error_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420.873906</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma  lambda  train_error  train_error_index\n",
       "3   0.02     0.0   420.873906                 59"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = tuningDF.loc[tuningDF.train_error>0, ]\n",
    "p[p['train_error'] == min(p['train_error'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running with optimal values of lambda, gamma and number of iterations to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = df2\n",
    "df4 = df4.fillna(0)\n",
    "# Changing pandas dataframes to numpy to make it easier\n",
    "df4 = df4.values\n",
    "df5 = df4.copy()\n",
    "def sse(true):\n",
    "    return np.sum(true**2)\n",
    "        \n",
    "lambdav = 0\n",
    "gamma=0.02\n",
    "# Latent factors for users\n",
    "P = np.ones((20, 2))\n",
    "# Latent factors for movie\n",
    "Q = np.ones((2, 20))\n",
    "\n",
    "\n",
    "\n",
    "train_errors = []\n",
    "num = 0\n",
    "while num < 60:\n",
    "    S = P.copy()\n",
    "    R = Q.copy()\n",
    "    errorlist = []\n",
    "    for a in range(0,20):\n",
    "        for b in range (0,20):\n",
    "            if df5[a,b] != 0:\n",
    "                df4[a,b] = df5[a,b] - np.dot(R[:,b], S[a, :].T)\n",
    "                errorlist.append((df4[a,b])**2)\n",
    "            else:\n",
    "                df4[a,b] = 0\n",
    "                \n",
    "    for c in range(0,20):\n",
    "        np.dot(df4[0, :], R[0,:])\n",
    "        P[c, 0] += gamma * (np.dot(df4[c, :], R[0,:]) - lambdav * P[c,0])\n",
    "        P[c, 1] += gamma * (np.dot(df4[c, :], R[1,:]) - lambdav * P[c,1])\n",
    "        Q[0, c] += gamma * (np.dot(df4[:, c], S[:,0]) - lambdav * Q[0, c]) \n",
    "        Q[1, c] += gamma * (np.dot(df4[:, c], S[:,1]) - lambdav * Q[1, c]) \n",
    "    num += 1\n",
    "    train_errors.append(sum(errorlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.237772</td>\n",
       "      <td>2.985970</td>\n",
       "      <td>2.828368</td>\n",
       "      <td>3.636431</td>\n",
       "      <td>3.187525</td>\n",
       "      <td>3.028465</td>\n",
       "      <td>2.924947</td>\n",
       "      <td>3.033753</td>\n",
       "      <td>3.208679</td>\n",
       "      <td>2.710539</td>\n",
       "      <td>3.088433</td>\n",
       "      <td>1.943864</td>\n",
       "      <td>2.831428</td>\n",
       "      <td>3.457131</td>\n",
       "      <td>3.243509</td>\n",
       "      <td>3.057010</td>\n",
       "      <td>3.136673</td>\n",
       "      <td>2.957210</td>\n",
       "      <td>3.050227</td>\n",
       "      <td>3.195640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.996430</td>\n",
       "      <td>2.763397</td>\n",
       "      <td>2.617542</td>\n",
       "      <td>3.365373</td>\n",
       "      <td>2.949928</td>\n",
       "      <td>2.802724</td>\n",
       "      <td>2.706922</td>\n",
       "      <td>2.807618</td>\n",
       "      <td>2.969505</td>\n",
       "      <td>2.508497</td>\n",
       "      <td>2.858222</td>\n",
       "      <td>1.798969</td>\n",
       "      <td>2.620375</td>\n",
       "      <td>3.199437</td>\n",
       "      <td>3.001739</td>\n",
       "      <td>2.829142</td>\n",
       "      <td>2.902866</td>\n",
       "      <td>2.736781</td>\n",
       "      <td>2.822864</td>\n",
       "      <td>2.957438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.679833</td>\n",
       "      <td>2.471421</td>\n",
       "      <td>2.340978</td>\n",
       "      <td>3.009794</td>\n",
       "      <td>2.638244</td>\n",
       "      <td>2.506594</td>\n",
       "      <td>2.420914</td>\n",
       "      <td>2.510971</td>\n",
       "      <td>2.655753</td>\n",
       "      <td>2.243454</td>\n",
       "      <td>2.556228</td>\n",
       "      <td>1.608893</td>\n",
       "      <td>2.343511</td>\n",
       "      <td>2.861390</td>\n",
       "      <td>2.684580</td>\n",
       "      <td>2.530220</td>\n",
       "      <td>2.596155</td>\n",
       "      <td>2.447617</td>\n",
       "      <td>2.524605</td>\n",
       "      <td>2.644960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.870047</td>\n",
       "      <td>2.646843</td>\n",
       "      <td>2.507140</td>\n",
       "      <td>3.223429</td>\n",
       "      <td>2.825507</td>\n",
       "      <td>2.684512</td>\n",
       "      <td>2.592750</td>\n",
       "      <td>2.689199</td>\n",
       "      <td>2.844258</td>\n",
       "      <td>2.402694</td>\n",
       "      <td>2.737669</td>\n",
       "      <td>1.723092</td>\n",
       "      <td>2.509853</td>\n",
       "      <td>3.064492</td>\n",
       "      <td>2.875132</td>\n",
       "      <td>2.709815</td>\n",
       "      <td>2.780430</td>\n",
       "      <td>2.621349</td>\n",
       "      <td>2.703802</td>\n",
       "      <td>2.832699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.453329</td>\n",
       "      <td>3.184762</td>\n",
       "      <td>3.016668</td>\n",
       "      <td>3.878528</td>\n",
       "      <td>3.399736</td>\n",
       "      <td>3.230087</td>\n",
       "      <td>3.119676</td>\n",
       "      <td>3.235727</td>\n",
       "      <td>3.422299</td>\n",
       "      <td>2.890995</td>\n",
       "      <td>3.294047</td>\n",
       "      <td>2.073277</td>\n",
       "      <td>3.019932</td>\n",
       "      <td>3.687291</td>\n",
       "      <td>3.459447</td>\n",
       "      <td>3.260532</td>\n",
       "      <td>3.345498</td>\n",
       "      <td>3.154088</td>\n",
       "      <td>3.253297</td>\n",
       "      <td>3.408391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.291136</td>\n",
       "      <td>3.035183</td>\n",
       "      <td>2.874984</td>\n",
       "      <td>3.696365</td>\n",
       "      <td>3.240060</td>\n",
       "      <td>3.078379</td>\n",
       "      <td>2.973154</td>\n",
       "      <td>3.083754</td>\n",
       "      <td>3.261563</td>\n",
       "      <td>2.755213</td>\n",
       "      <td>3.139335</td>\n",
       "      <td>1.975901</td>\n",
       "      <td>2.878095</td>\n",
       "      <td>3.514109</td>\n",
       "      <td>3.296967</td>\n",
       "      <td>3.107395</td>\n",
       "      <td>3.188370</td>\n",
       "      <td>3.005950</td>\n",
       "      <td>3.100499</td>\n",
       "      <td>3.248309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.556303</td>\n",
       "      <td>2.357498</td>\n",
       "      <td>2.233068</td>\n",
       "      <td>2.871054</td>\n",
       "      <td>2.516631</td>\n",
       "      <td>2.391049</td>\n",
       "      <td>2.309319</td>\n",
       "      <td>2.395225</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>2.140039</td>\n",
       "      <td>2.438396</td>\n",
       "      <td>1.534729</td>\n",
       "      <td>2.235484</td>\n",
       "      <td>2.729492</td>\n",
       "      <td>2.560832</td>\n",
       "      <td>2.413587</td>\n",
       "      <td>2.476482</td>\n",
       "      <td>2.334792</td>\n",
       "      <td>2.408231</td>\n",
       "      <td>2.523038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.026098</td>\n",
       "      <td>2.790757</td>\n",
       "      <td>2.643459</td>\n",
       "      <td>3.398693</td>\n",
       "      <td>2.979135</td>\n",
       "      <td>2.830474</td>\n",
       "      <td>2.733723</td>\n",
       "      <td>2.835417</td>\n",
       "      <td>2.998906</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>2.886522</td>\n",
       "      <td>1.816780</td>\n",
       "      <td>2.646319</td>\n",
       "      <td>3.231115</td>\n",
       "      <td>3.031459</td>\n",
       "      <td>2.857153</td>\n",
       "      <td>2.931608</td>\n",
       "      <td>2.763878</td>\n",
       "      <td>2.850813</td>\n",
       "      <td>2.986719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.418873</td>\n",
       "      <td>3.152986</td>\n",
       "      <td>2.986569</td>\n",
       "      <td>3.839830</td>\n",
       "      <td>3.365815</td>\n",
       "      <td>3.197858</td>\n",
       "      <td>3.088550</td>\n",
       "      <td>3.203443</td>\n",
       "      <td>3.388153</td>\n",
       "      <td>2.862150</td>\n",
       "      <td>3.261181</td>\n",
       "      <td>2.052591</td>\n",
       "      <td>2.989801</td>\n",
       "      <td>3.650501</td>\n",
       "      <td>3.424930</td>\n",
       "      <td>3.228000</td>\n",
       "      <td>3.312119</td>\n",
       "      <td>3.122618</td>\n",
       "      <td>3.220837</td>\n",
       "      <td>3.374384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.357150</td>\n",
       "      <td>3.096063</td>\n",
       "      <td>2.932651</td>\n",
       "      <td>3.770507</td>\n",
       "      <td>3.305050</td>\n",
       "      <td>3.140125</td>\n",
       "      <td>3.032790</td>\n",
       "      <td>3.145609</td>\n",
       "      <td>3.326984</td>\n",
       "      <td>2.810478</td>\n",
       "      <td>3.202304</td>\n",
       "      <td>2.015534</td>\n",
       "      <td>2.935824</td>\n",
       "      <td>3.584596</td>\n",
       "      <td>3.363098</td>\n",
       "      <td>3.169723</td>\n",
       "      <td>3.252323</td>\n",
       "      <td>3.066243</td>\n",
       "      <td>3.162689</td>\n",
       "      <td>3.313463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.071352</td>\n",
       "      <td>2.832492</td>\n",
       "      <td>2.682991</td>\n",
       "      <td>3.449520</td>\n",
       "      <td>3.023688</td>\n",
       "      <td>2.872803</td>\n",
       "      <td>2.774606</td>\n",
       "      <td>2.877820</td>\n",
       "      <td>3.043755</td>\n",
       "      <td>2.571219</td>\n",
       "      <td>2.929689</td>\n",
       "      <td>1.843950</td>\n",
       "      <td>2.685894</td>\n",
       "      <td>3.279436</td>\n",
       "      <td>3.076794</td>\n",
       "      <td>2.899882</td>\n",
       "      <td>2.975449</td>\n",
       "      <td>2.805211</td>\n",
       "      <td>2.893447</td>\n",
       "      <td>3.031385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.852301</td>\n",
       "      <td>2.630477</td>\n",
       "      <td>2.491638</td>\n",
       "      <td>3.203498</td>\n",
       "      <td>2.808036</td>\n",
       "      <td>2.667913</td>\n",
       "      <td>2.576719</td>\n",
       "      <td>2.672571</td>\n",
       "      <td>2.826671</td>\n",
       "      <td>2.387837</td>\n",
       "      <td>2.720741</td>\n",
       "      <td>1.712438</td>\n",
       "      <td>2.494334</td>\n",
       "      <td>3.045543</td>\n",
       "      <td>2.857354</td>\n",
       "      <td>2.693059</td>\n",
       "      <td>2.763238</td>\n",
       "      <td>2.605141</td>\n",
       "      <td>2.687083</td>\n",
       "      <td>2.815184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.984926</td>\n",
       "      <td>3.675017</td>\n",
       "      <td>3.481047</td>\n",
       "      <td>4.475580</td>\n",
       "      <td>3.923083</td>\n",
       "      <td>3.727319</td>\n",
       "      <td>3.599912</td>\n",
       "      <td>3.733827</td>\n",
       "      <td>3.949119</td>\n",
       "      <td>3.336028</td>\n",
       "      <td>3.801125</td>\n",
       "      <td>2.392433</td>\n",
       "      <td>3.484813</td>\n",
       "      <td>4.254904</td>\n",
       "      <td>3.991986</td>\n",
       "      <td>3.762451</td>\n",
       "      <td>3.860497</td>\n",
       "      <td>3.639621</td>\n",
       "      <td>3.754102</td>\n",
       "      <td>3.933070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.869928</td>\n",
       "      <td>2.646732</td>\n",
       "      <td>2.507036</td>\n",
       "      <td>3.223294</td>\n",
       "      <td>2.825389</td>\n",
       "      <td>2.684400</td>\n",
       "      <td>2.592642</td>\n",
       "      <td>2.689087</td>\n",
       "      <td>2.844140</td>\n",
       "      <td>2.402594</td>\n",
       "      <td>2.737555</td>\n",
       "      <td>1.723020</td>\n",
       "      <td>2.509748</td>\n",
       "      <td>3.064364</td>\n",
       "      <td>2.875012</td>\n",
       "      <td>2.709702</td>\n",
       "      <td>2.780314</td>\n",
       "      <td>2.621240</td>\n",
       "      <td>2.703689</td>\n",
       "      <td>2.832581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.434520</td>\n",
       "      <td>3.167416</td>\n",
       "      <td>3.000238</td>\n",
       "      <td>3.857404</td>\n",
       "      <td>3.381219</td>\n",
       "      <td>3.212494</td>\n",
       "      <td>3.102685</td>\n",
       "      <td>3.218104</td>\n",
       "      <td>3.403659</td>\n",
       "      <td>2.875249</td>\n",
       "      <td>3.276106</td>\n",
       "      <td>2.061985</td>\n",
       "      <td>3.003484</td>\n",
       "      <td>3.667208</td>\n",
       "      <td>3.440605</td>\n",
       "      <td>3.242774</td>\n",
       "      <td>3.327277</td>\n",
       "      <td>3.136909</td>\n",
       "      <td>3.235578</td>\n",
       "      <td>3.389827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.053159</td>\n",
       "      <td>2.815714</td>\n",
       "      <td>2.667099</td>\n",
       "      <td>3.429087</td>\n",
       "      <td>3.005777</td>\n",
       "      <td>2.855786</td>\n",
       "      <td>2.758171</td>\n",
       "      <td>2.860773</td>\n",
       "      <td>3.025725</td>\n",
       "      <td>2.555988</td>\n",
       "      <td>2.912335</td>\n",
       "      <td>1.833027</td>\n",
       "      <td>2.669984</td>\n",
       "      <td>3.260010</td>\n",
       "      <td>3.058569</td>\n",
       "      <td>2.882704</td>\n",
       "      <td>2.957824</td>\n",
       "      <td>2.788594</td>\n",
       "      <td>2.876307</td>\n",
       "      <td>3.013429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.935410</td>\n",
       "      <td>2.707122</td>\n",
       "      <td>2.564238</td>\n",
       "      <td>3.296839</td>\n",
       "      <td>2.889855</td>\n",
       "      <td>2.745649</td>\n",
       "      <td>2.651798</td>\n",
       "      <td>2.750443</td>\n",
       "      <td>2.909033</td>\n",
       "      <td>2.457413</td>\n",
       "      <td>2.800017</td>\n",
       "      <td>1.762334</td>\n",
       "      <td>2.567012</td>\n",
       "      <td>3.134283</td>\n",
       "      <td>2.940610</td>\n",
       "      <td>2.771528</td>\n",
       "      <td>2.843751</td>\n",
       "      <td>2.681048</td>\n",
       "      <td>2.765378</td>\n",
       "      <td>2.897211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.215949</td>\n",
       "      <td>2.965844</td>\n",
       "      <td>2.809304</td>\n",
       "      <td>3.611921</td>\n",
       "      <td>3.166040</td>\n",
       "      <td>3.008053</td>\n",
       "      <td>2.905232</td>\n",
       "      <td>3.013305</td>\n",
       "      <td>3.187052</td>\n",
       "      <td>2.692270</td>\n",
       "      <td>3.067616</td>\n",
       "      <td>1.930762</td>\n",
       "      <td>2.812344</td>\n",
       "      <td>3.433829</td>\n",
       "      <td>3.221647</td>\n",
       "      <td>3.036405</td>\n",
       "      <td>3.115531</td>\n",
       "      <td>2.937278</td>\n",
       "      <td>3.029667</td>\n",
       "      <td>3.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.812413</td>\n",
       "      <td>2.593691</td>\n",
       "      <td>2.456794</td>\n",
       "      <td>3.158698</td>\n",
       "      <td>2.768767</td>\n",
       "      <td>2.630603</td>\n",
       "      <td>2.540684</td>\n",
       "      <td>2.635197</td>\n",
       "      <td>2.787142</td>\n",
       "      <td>2.354445</td>\n",
       "      <td>2.682693</td>\n",
       "      <td>1.688490</td>\n",
       "      <td>2.459452</td>\n",
       "      <td>3.002953</td>\n",
       "      <td>2.817396</td>\n",
       "      <td>2.655398</td>\n",
       "      <td>2.724595</td>\n",
       "      <td>2.568709</td>\n",
       "      <td>2.649506</td>\n",
       "      <td>2.775815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.214397</td>\n",
       "      <td>2.964412</td>\n",
       "      <td>2.807948</td>\n",
       "      <td>3.610177</td>\n",
       "      <td>3.164512</td>\n",
       "      <td>3.006601</td>\n",
       "      <td>2.903830</td>\n",
       "      <td>3.011851</td>\n",
       "      <td>3.185514</td>\n",
       "      <td>2.690970</td>\n",
       "      <td>3.066136</td>\n",
       "      <td>1.929830</td>\n",
       "      <td>2.810986</td>\n",
       "      <td>3.432171</td>\n",
       "      <td>3.220092</td>\n",
       "      <td>3.034940</td>\n",
       "      <td>3.114027</td>\n",
       "      <td>2.935860</td>\n",
       "      <td>3.028205</td>\n",
       "      <td>3.172568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7   \\\n",
       "1   3.237772  2.985970  2.828368  3.636431  3.187525  3.028465  2.924947   \n",
       "2   2.996430  2.763397  2.617542  3.365373  2.949928  2.802724  2.706922   \n",
       "3   2.679833  2.471421  2.340978  3.009794  2.638244  2.506594  2.420914   \n",
       "4   2.870047  2.646843  2.507140  3.223429  2.825507  2.684512  2.592750   \n",
       "5   3.453329  3.184762  3.016668  3.878528  3.399736  3.230087  3.119676   \n",
       "6   3.291136  3.035183  2.874984  3.696365  3.240060  3.078379  2.973154   \n",
       "7   2.556303  2.357498  2.233068  2.871054  2.516631  2.391049  2.309319   \n",
       "8   3.026098  2.790757  2.643459  3.398693  2.979135  2.830474  2.733723   \n",
       "9   3.418873  3.152986  2.986569  3.839830  3.365815  3.197858  3.088550   \n",
       "10  3.357150  3.096063  2.932651  3.770507  3.305050  3.140125  3.032790   \n",
       "11  3.071352  2.832492  2.682991  3.449520  3.023688  2.872803  2.774606   \n",
       "12  2.852301  2.630477  2.491638  3.203498  2.808036  2.667913  2.576719   \n",
       "13  3.984926  3.675017  3.481047  4.475580  3.923083  3.727319  3.599912   \n",
       "14  2.869928  2.646732  2.507036  3.223294  2.825389  2.684400  2.592642   \n",
       "15  3.434520  3.167416  3.000238  3.857404  3.381219  3.212494  3.102685   \n",
       "16  3.053159  2.815714  2.667099  3.429087  3.005777  2.855786  2.758171   \n",
       "17  2.935410  2.707122  2.564238  3.296839  2.889855  2.745649  2.651798   \n",
       "18  3.215949  2.965844  2.809304  3.611921  3.166040  3.008053  2.905232   \n",
       "19  2.812413  2.593691  2.456794  3.158698  2.768767  2.630603  2.540684   \n",
       "20  3.214397  2.964412  2.807948  3.610177  3.164512  3.006601  2.903830   \n",
       "\n",
       "          8         9         10        11        12        13        14  \\\n",
       "1   3.033753  3.208679  2.710539  3.088433  1.943864  2.831428  3.457131   \n",
       "2   2.807618  2.969505  2.508497  2.858222  1.798969  2.620375  3.199437   \n",
       "3   2.510971  2.655753  2.243454  2.556228  1.608893  2.343511  2.861390   \n",
       "4   2.689199  2.844258  2.402694  2.737669  1.723092  2.509853  3.064492   \n",
       "5   3.235727  3.422299  2.890995  3.294047  2.073277  3.019932  3.687291   \n",
       "6   3.083754  3.261563  2.755213  3.139335  1.975901  2.878095  3.514109   \n",
       "7   2.395225  2.533333  2.140039  2.438396  1.534729  2.235484  2.729492   \n",
       "8   2.835417  2.998906  2.533333  2.886522  1.816780  2.646319  3.231115   \n",
       "9   3.203443  3.388153  2.862150  3.261181  2.052591  2.989801  3.650501   \n",
       "10  3.145609  3.326984  2.810478  3.202304  2.015534  2.935824  3.584596   \n",
       "11  2.877820  3.043755  2.571219  2.929689  1.843950  2.685894  3.279436   \n",
       "12  2.672571  2.826671  2.387837  2.720741  1.712438  2.494334  3.045543   \n",
       "13  3.733827  3.949119  3.336028  3.801125  2.392433  3.484813  4.254904   \n",
       "14  2.689087  2.844140  2.402594  2.737555  1.723020  2.509748  3.064364   \n",
       "15  3.218104  3.403659  2.875249  3.276106  2.061985  3.003484  3.667208   \n",
       "16  2.860773  3.025725  2.555988  2.912335  1.833027  2.669984  3.260010   \n",
       "17  2.750443  2.909033  2.457413  2.800017  1.762334  2.567012  3.134283   \n",
       "18  3.013305  3.187052  2.692270  3.067616  1.930762  2.812344  3.433829   \n",
       "19  2.635197  2.787142  2.354445  2.682693  1.688490  2.459452  3.002953   \n",
       "20  3.011851  3.185514  2.690970  3.066136  1.929830  2.810986  3.432171   \n",
       "\n",
       "          15        16        17        18        19        20  \n",
       "1   3.243509  3.057010  3.136673  2.957210  3.050227  3.195640  \n",
       "2   3.001739  2.829142  2.902866  2.736781  2.822864  2.957438  \n",
       "3   2.684580  2.530220  2.596155  2.447617  2.524605  2.644960  \n",
       "4   2.875132  2.709815  2.780430  2.621349  2.703802  2.832699  \n",
       "5   3.459447  3.260532  3.345498  3.154088  3.253297  3.408391  \n",
       "6   3.296967  3.107395  3.188370  3.005950  3.100499  3.248309  \n",
       "7   2.560832  2.413587  2.476482  2.334792  2.408231  2.523038  \n",
       "8   3.031459  2.857153  2.931608  2.763878  2.850813  2.986719  \n",
       "9   3.424930  3.228000  3.312119  3.122618  3.220837  3.374384  \n",
       "10  3.363098  3.169723  3.252323  3.066243  3.162689  3.313463  \n",
       "11  3.076794  2.899882  2.975449  2.805211  2.893447  3.031385  \n",
       "12  2.857354  2.693059  2.763238  2.605141  2.687083  2.815184  \n",
       "13  3.991986  3.762451  3.860497  3.639621  3.754102  3.933070  \n",
       "14  2.875012  2.709702  2.780314  2.621240  2.703689  2.832581  \n",
       "15  3.440605  3.242774  3.327277  3.136909  3.235578  3.389827  \n",
       "16  3.058569  2.882704  2.957824  2.788594  2.876307  3.013429  \n",
       "17  2.940610  2.771528  2.843751  2.681048  2.765378  2.897211  \n",
       "18  3.221647  3.036405  3.115531  2.937278  3.029667  3.174100  \n",
       "19  2.817396  2.655398  2.724595  2.568709  2.649506  2.775815  \n",
       "20  3.220092  3.034940  3.114027  2.935860  3.028205  3.172568  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.dot(P, Q)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.index = predictions.index + 1\n",
    "predictions.columns = predictions.columns + 1\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
